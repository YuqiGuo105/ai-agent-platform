spring:
  application:
    name: MrPot

  codec:
    max-in-memory-size: 10MB

  # === PostgreSQL (Railway pgvector database) ===
  datasource:
    url: ${DB_URL:jdbc:postgresql://centerbeam.proxy.rlwy.net:27055/railway}
    username: ${DB_USERNAME:postgres}
    password: ${DB_PASSWORD}
    driver-class-name: org.postgresql.Driver

  jpa:
    hibernate:
      ddl-auto: update
    properties:
      hibernate:
        format_sql: true
    show-sql: false

  # === Redis (Railway Redis instance) ===
  data:
    redis:
      url: ${REDIS_URL}
      timeout: 3000

  cache:
    type: redis

  # === Spring AI Model Configuration ===
  ai:
    # --- OpenAI (ChatGPT / Embedding for RAG) ---
    openai:
      api-key: ${OPENAI_API_KEY}
      # Chat model (streaming SSE with ChatClient)
      chat:
        options:
          model: ${OPENAI_CHAT_MODEL:gpt-4.1-mini}
          temperature: ${OPENAI_TEMPERATURE:0.3}
      # Embedding model for pgvector
      embedding:
        options:
          model: ${OPENAI_EMBEDDING_MODEL:text-embedding-3-small}
          dimensions: ${OPENAI_EMBEDDING_DIMENSIONS:1536}

    # --- DeepSeek ---
    deepseek:
      api-key: ${DEEPSEEK_API_KEY}
      base-url: ${DEEPSEEK_BASE_URL:https://api.deepseek.com}
      chat:
        options:
          # Specific model: deepseek-chat / deepseek-reasoner etc.
          model: ${DEEPSEEK_CHAT_MODEL:deepseek-chat}
          temperature: ${DEEPSEEK_TEMPERATURE:0.2}

    # --- Google Gemini (via spring-ai-starter-model-google-genai) ---
    google:
      genai:
        api-key: ${GEMINI_API_KEY:}
        chat:
          options:
            # Specific model: use latest flash / pro etc.
            model: ${GEMINI_CHAT_MODEL:gemini-2.0-flash}
            temperature: ${GEMINI_TEMPERATURE:0.3}

    # --- DashScope (for Alibaba Cloud Qwen ecosystem) ---
    dashscope:
      base-url: ${DASHSCOPE_BASE_URL:https://dashscope-intl.aliyuncs.com/compatible-mode/v1}
      api-key: ${DASHSCOPE_API_KEY}

      chat:
        options:
          model: ${DASHSCOPE_CHAT_MODEL:qwen-vl-plus}
          temperature: ${QWEN_TEMPERATURE:0.1}
          max-tokens: ${QWEN_MAX_TOKENS:2048}
          enable-thinking: ${QWEN_ENABLE_THINKING:false}

    # === PGVector vector store configuration (for RAG) ===
    vectorstore:
      pgvector:
        # Let Spring AI auto-create tables (convenient for first use)
        initialize-schema: true
        index-type: HNSW
        distance-type: COSINE_DISTANCE
        # Must match embedding model dimensions above
        dimensions: ${PGVECTOR_DIMENSIONS:1536}
        # Uses main DataSource (Postgres above) by default

# MrPot service port (Railway will provide PORT)
server:
  port: ${PORT:8080}

# === Swagger UI / OpenAPI Documentation ===
springdoc:
  swagger-ui:
    path: /swagger-ui
  api-docs:
    path: /v3/api-docs

# === Actuator / Monitoring (optional) ===
management:
  endpoints:
    web:
      exposure:
        include: health,info,prometheus
  endpoint:
    health:
      show-details: when_authorized

# === CORS configuration ===
cors:
  # Comma-separated env value (CORS_ALLOWED_ORIGINS) will be split into a list.
  allowed-origins: ${CORS_ALLOWED_ORIGINS:*}
  allowed-methods:
    - GET
    - POST
    - PUT
    - DELETE
    - PATCH
    - OPTIONS
  allowed-headers:
    - "*"
  allow-credentials: false

app:
  elastic:
    base-url: ${ELASTIC_BASE_URL:https://elasticsearch-production-361a.up.railway.app}
    username: ${ELASTIC_USERNAME:mrpot}
    password: ${ELASTIC_PASSWORD}
  candidate:
    store-to-es: ${ELASTIC_STORE_TO_ES:true}
    es-sync: ${ELASTIC_ES_SYNC:true}
    es-index: ${ELASTIC_ES_INDEX:mrpot_candidates}

mcp:
  tools:
    base-url: ${TOOLS_SERVICE_URL:http://localhost:8081}
  registry:
    default-ttl-seconds: 300
  call:
    timeout-ms: 30000
    max-retries: 1
  debug:
    allow-explicit-tool: true

file:
  max-urls: 3
  attach-timeout-seconds: 30
  max-concurrent: 2
